{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging tweets with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Feb  4 21:11:00 2018\n",
    "\n",
    "@author: Pooja\n",
    "www.poojaangurala.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split # function for splitting data to train and test sets\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "#from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "from subprocess import check_output\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('reviews.csv')\n",
    "data1 = data[['review_title']]\n",
    "\n",
    "with open(\"pos.txt\", \"r\") as f:\n",
    "    posText = f.read()\n",
    "posTokens = posText.split(\"\\n\") # This splits the text file into tokens on the new line character\n",
    "posTokens[-1:] = [] # This strips out the final empty item\n",
    "print(posTokens[-10:])\n",
    "with open(\"neg.txt\", \"r\") as f:\n",
    "    negText = f.read()\n",
    "negTokens = negText.split(\"\\n\") # This splits the text file into tokens on the new line character\n",
    "negTokens[-1:] = [] # This strips out the final empty item\n",
    "print(negTokens[-10:])\n",
    "posTokens.append(\"spectacular\")\n",
    "posTokens.append(\"everyday\")\n",
    "posTokens.append(\"better\")\n",
    "posTokens.append(\"top\")\n",
    "posTokens.append(\"thumbs\")\n",
    "posTokens.append(\"four\")\n",
    "posTokens.append(\"five\")\n",
    "negTokens.append(\"one\")\n",
    "negTokens.append(\"two\")\n",
    "negTokens.append(\"careful\")\n",
    "negTokens.append(\"sync\")\n",
    "negTokens.append(\"Beware\")\n",
    "negTokens.append(\"suck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negTokens=negTokens[35:]\n",
    "posTokens=posTokens[35:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos_words = nltk.FreqDist(posTokens)\n",
    "pos_word_features = list(all_pos_words.keys())\n",
    "features_p = {}\n",
    "def pos_tweet_token(tweets):\n",
    "    t_words = set(tweets)\n",
    "    for w in pos_word_features:\n",
    "        features_p[w] = (w in t_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_neg_words = nltk.FreqDist(negTokens)\n",
    "neg_word_features = list(all_neg_words.keys())\n",
    "features_n = {}\n",
    "def neg_tweet_token(tweets):\n",
    "    t_words = set(tweets)\n",
    "    for w in neg_word_features:\n",
    "        features_n[w] = (w in t_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_cat(data):\n",
    "    cat=[]\n",
    "    sent_token=[]\n",
    "    for t in data['review_title']:\n",
    "        sent_token.append(word_tokenize(t))\n",
    "    for s in sent_token:\n",
    "        #s.lower()\n",
    "        words = set(s)\n",
    "        #words.lower()\n",
    "        stop_words=['!','$','%',\"'m\",\"'re\",\"'s\",\"'ve\",'(',')',',','-','--','..', '...','.its','1','100','11','2','200','2hrs','3','3rd','4.0','6','8',':','?','``']\n",
    "        clean_tweet= [i for i in words if not i in stop_words]\n",
    "        clean_L_tweet=[]\n",
    "        for i in clean_tweet:\n",
    "            w=i.lower()\n",
    "            #w.lower()\n",
    "            clean_L_tweet.append(w)\n",
    "        neg_tweet_token(clean_L_tweet)\n",
    "        countn=0\n",
    "        for fn, value in features_n.items():\n",
    "            if value == True:\n",
    "                countn=countn+1\n",
    "        pos_tweet_token(clean_L_tweet)\n",
    "        countp=0\n",
    "        for key, value in features_p.items():\n",
    "            if value == True:\n",
    "                countp=countp+1\n",
    "        if countp>countn:\n",
    "            cat.append('pos')\n",
    "        elif countp<countn:\n",
    "            cat.append('neg')\n",
    "        elif countp==countn:\n",
    "            cat.append('nu')\n",
    "    data['cat'] = cat\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_cat(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_POS=0\n",
    "count_NEG=0\n",
    "count_NU=0\n",
    "for i in data1['cat']:\n",
    "    if i =='pos':\n",
    "        count_POS=count_POS+1\n",
    "    if i =='neg':\n",
    "        count_NEG = count_NEG+1\n",
    "    if i=='nu':\n",
    "        count_NU = count_NU+1\n",
    "print (\"Total Pos: \",count_POS )\n",
    "print (\"Total Neg: \", count_NEG)\n",
    "print (\"Total Nu: \", count_NU)\n",
    "print (\"Total_count: \", len(data1['cat']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

